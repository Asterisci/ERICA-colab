{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ERICA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAhTPI1-cnhO"
      },
      "source": [
        "# ERICA-colab\n",
        "\n",
        "\n",
        "The repo is forked from thunlp/ERICA, and then change some wrong codes and adjust codes for using in google colab and other online jupyter notebook.\n",
        "\n",
        "Github repo: https://github.com/chaoers/ERICA-colab "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cosnv79Lcuic"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg2rgTlD29dz"
      },
      "source": [
        "! git clone https://github.com/chaoers/ERICA.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_OTDuaV7NuX"
      },
      "source": [
        "! pip install folium==0.2.1;pip install transformers==2.5.0;pip install pytorch_metric_learning==0.9.81;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thprZ-b454a3"
      },
      "source": [
        "! git clone https://github.com/NVIDIA/apex; cd apex; pip install -v --disable-pip-version-check --no-cache-dir ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_580zQ0fu36"
      },
      "source": [
        "## Download model file(optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzfXZEKcFrIu"
      },
      "source": [
        "! cd ERICA/pretrain/code/pretrain; mkdir temp; cd temp; \\\n",
        "wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt; \\\n",
        "wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt; \\\n",
        "wget https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json; \\\n",
        "wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin; \\\n",
        "wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin; \\\n",
        "wget https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPKAGGoPgCVX"
      },
      "source": [
        "## Pretraining(use local model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwX24cmb-egA"
      },
      "source": [
        "! cd ERICA/pretrain/code/pretrain; python -m torch.distributed.launch --nproc_per_node 1  main.py  \\\n",
        "    --model DOC  --lr 3e-5 --batch_size_per_gpu 8 --max_epoch 1  \\\n",
        "    --gradient_accumulation_steps 16    --save_step 1  --temperature 0.05  \\\n",
        "    --train_sample  --save_dir ckpt_doc_dw_f_alpha_1_uncased --n_gpu 1  --debug 1  --add_none 1 \\\n",
        "    --alpha 1 --flow 0 --dataset_name none.json  --wiki_loss 1 --doc_loss 1 \\\n",
        "    --change_dataset 1  --start_end_token 0 --bert_model bert \\\n",
        "    --pretraining_size -1 --ablation 0 --cased 0 --cuda 0 --local_rank 0 --local_dir ./temp/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}